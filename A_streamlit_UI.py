import streamlit as st
import os
import re
from A_audio_extractor import extract_audio_from_video
from A_audio_recognition import transcribe_audio
from A_video_analyzer import process_video
from A_model_inference import summarize_video_from_all_frames
import json
import subprocess
import time
import tempfile

# æ–‡ä»¶ä¿å­˜åŸºç¡€è·¯å¾„
save_dir = "G:/videochat/my_design/streamlit_save"
os.makedirs(save_dir, exist_ok=True)

st.set_page_config(page_title="åŸºäºAIå¤§æ¨¡å‹çš„è§†é¢‘è¯­ä¹‰åˆ†æç³»ç»Ÿ", layout="wide")

# ========== å·¦ä¾§æ“ä½œåŒº ==========
with st.sidebar:
    st.header("ğŸ›  æ“ä½œè®¾ç½®")

    # ä¸Šä¼ è§†é¢‘
    uploaded_video = st.file_uploader("ğŸ¥ ä¸Šä¼ è§†é¢‘", type=["mp4"])


    #å¯åŠ¨sensevoiceæœåŠ¡å™¨
    if st.button("ğŸš€ å¯åŠ¨æœ¬åœ° SenseVoiceæœåŠ¡å™¨"):
        server_path = "G:/videochat/my_design/start_sensevoice_server.py"
        try:
            subprocess.Popen(["python", server_path], creationflags=subprocess.CREATE_NEW_CONSOLE)
            st.success("âœ… æ­£åœ¨å¯åŠ¨ SenseVoice æœåŠ¡å™¨")
        except Exception as e:
            st.error(f"âŒ å¯åŠ¨å¤±è´¥ï¼š{e}")

    # å¤§æ¨¡å‹ API é€‰æ‹©
    api_choice = st.selectbox("ğŸ¤– é€‰æ‹©å¤§æ¨¡å‹ API", ["DashScope", "OpenAI", "æœ¬åœ°Qwen"])

    # å‚æ•°æ§åˆ¶
    frame_interval = st.slider("ğŸ“ æŠ½å¸§é—´éš”ï¼ˆç§’ï¼‰", min_value=1, max_value=10, value=2)
    text_threshold = st.number_input("ğŸ“š æ–‡æœ¬æŠ½å¸§å­—æ•°é˜ˆå€¼", min_value=10, value=80)


#åŠŸèƒ½è§¦å‘
transcribe_triggered = False#b1ç”¨

# ========== é¡µé¢å³ä¾§åŠŸèƒ½æŒ‰é’®ä¸è¾“å‡ºå±•ç¤º ==========
st.title("ğŸ¬ éŸ³è§†é¢‘è¯­ä¹‰åˆ†æç³»ç»Ÿ")
st.markdown("ä¸Šä¼ è§†é¢‘å¹¶ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æ‰§è¡Œå„ç±»åˆ†æåŠŸèƒ½ã€‚")
output_text = ""
b1, b2, b3, b4 = st.columns(4)

with b1:
    if st.button("ğŸ“ æ–‡æœ¬è½¬å½•"):
        transcribe_triggered = True
        if uploaded_video:
            video_raw_name = uploaded_video.name
            video_name = os.path.splitext(video_raw_name)[0]
            # --- å®šä¹‰æ°¸ä¹…æ–‡ä»¶ä¿å­˜ç›®å½• ---
            video_dir = os.path.join(save_dir, video_name) # ä½¿ç”¨ save_dir å˜é‡
            os.makedirs(video_dir, exist_ok=True)

            # --- å®šä¹‰éœ€è¦æ°¸ä¹…ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ ---
            audio_path = os.path.join(video_dir, f"{video_name}.mp3")
            json_path = os.path.join(video_dir, f"{video_name}_transcription.json")
            text_path = os.path.join(video_dir, f"{video_name}_clean.txt")

            temp_video_path = None # åˆå§‹åŒ–ä¸´æ—¶è§†é¢‘è·¯å¾„å˜é‡
            try:
                # --- 1. å°†ä¸Šä¼ çš„è§†é¢‘å†™å…¥ä¸´æ—¶æ–‡ä»¶ ---
                with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as temp_video_file:
                    temp_video_path = temp_video_file.name
                    # å°†ä¸Šä¼ æ–‡ä»¶ç¼“å†²åŒºçš„å†…å®¹å†™å…¥ä¸´æ—¶æ–‡ä»¶
                    temp_video_file.write(uploaded_video.getbuffer())
                    # (å¯é€‰) æ‰“å°ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼Œæ–¹ä¾¿è°ƒè¯•
                    # st.write(f"â³ è§†é¢‘å·²æš‚å­˜è‡³: `{temp_video_path}` (å¤„ç†åå°†åˆ é™¤)")

                # --- 2. ä½¿ç”¨ä¸´æ—¶è§†é¢‘æ–‡ä»¶æå–éŸ³é¢‘ (ä¿å­˜åˆ°æ°¸ä¹…è·¯å¾„ audio_path) ---
                extract_audio_from_video(temp_video_path, audio_path)

                # --- 3. æ‰§è¡Œè½¬å½• (ä½¿ç”¨æ°¸ä¹…ä¿å­˜çš„éŸ³é¢‘æ–‡ä»¶) ---

                api_key = "sk-xxx" # è®°å¾—æ›¿æ¢æˆä½ çš„å®é™… API Key æˆ–ä»é…ç½®ä¸­è¯»å–
                transcription = transcribe_audio(audio_path, api_key)

                # --- 4. ä¿å­˜åŸå§‹ JSON è½¬å½•ç»“æœ (ä¿å­˜åˆ°æ°¸ä¹…è·¯å¾„ json_path) ---
                if transcription is not None:
                    with open(json_path, "w", encoding="utf-8") as f:
                        json.dump(transcription, f, ensure_ascii=False, indent=2)

                    # --- 5. æ¸…æ´—åˆå¹¶æ–‡æœ¬ (ä¿å­˜åˆ°æ°¸ä¹…è·¯å¾„ text_path) ---
                    clean_text = ""
                    # æ£€æŸ¥ transcription æ˜¯å¦æ˜¯é¢„æœŸçš„åˆ—è¡¨æ ¼å¼
                    if isinstance(transcription, list):
                        for seg in transcription:
                            line = seg.get("text", "")
                            # ä¿ç•™ä¸€äº›åŸºæœ¬æ ‡ç‚¹ç¬¦å·ï¼Œè®©æ–‡æœ¬æ›´æ˜“è¯»
                            line = re.sub(r"[^\u4e00-\u9fa5a-zA-Z0-9ï¼Œã€‚ï¼ï¼Ÿã€Šã€‹â€œâ€ï¼šï¼›ï¼ˆï¼‰()ã€â€¦,.!?]", "", line)
                            clean_text += line + " "
                    elif isinstance(transcription, dict) and "res" in transcription:
                         # å…¼å®¹ A_audio_recognition.py è¿”å›åŸå§‹ dict çš„æƒ…å†µ
                         if isinstance(transcription["res"], list):
                             for seg in transcription["res"]:
                                 line = seg.get("text", "")
                                 line = re.sub(r"[^\u4e00-\u9fa5a-zA-Z0-9ï¼Œã€‚ï¼ï¼Ÿã€Šã€‹â€œâ€ï¼šï¼›ï¼ˆï¼‰()ã€â€¦,.!?]", "", line)
                                 clean_text += line + " "
                         else:
                             st.error("âŒ è½¬å½•ç»“æœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ (res is not list)ã€‚")
                             clean_text = "è½¬å½•ç»“æœæ ¼å¼é”™è¯¯"
                    else:
                        st.error("âŒ è½¬å½•ç»“æœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ (ä¸æ˜¯åˆ—è¡¨æˆ–åŒ…å«'res'åˆ—è¡¨çš„å­—å…¸)ã€‚")
                        clean_text = "è½¬å½•ç»“æœæ ¼å¼é”™è¯¯" # æä¾›é”™è¯¯ä¿¡æ¯

                    clean_text = clean_text.strip()
                    with open(text_path, "w", encoding="utf-8") as f:
                        f.write(clean_text)

                    # å°†å†…å®¹å†™å…¥ç»Ÿä¸€è¾“å‡ºæ¡†
                    output_text = clean_text
                else:
                    st.error("âŒ è¯­éŸ³è½¬å½•å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆåç»­æ–‡ä»¶ã€‚")
                    output_text = "è¯­éŸ³è½¬å½•å¤±è´¥" # æ›´æ–°è¾“å‡ºæ¡†çŠ¶æ€

            except Exception as e:
                st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                output_text = f"å¤„ç†å¤±è´¥: {e}" # åœ¨è¾“å‡ºæ¡†æ˜¾ç¤ºé”™è¯¯
            finally:
                # --- 6. æ¸…ç†ä¸´æ—¶è§†é¢‘æ–‡ä»¶ ---
                if temp_video_path and os.path.exists(temp_video_path):
                    try:
                        os.remove(temp_video_path)
                        # (å¯é€‰) æ‰“å°åˆ é™¤ç¡®è®¤ä¿¡æ¯
                        # st.write(f"ğŸ—‘ï¸ ä¸´æ—¶è§†é¢‘æ–‡ä»¶ `{temp_video_path}` å·²åˆ é™¤ã€‚")
                    except Exception as e_del:
                        st.warning(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶ `{temp_video_path}` å¤±è´¥: {e_del}")

        else:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶")
with b2:
    if st.button("ğŸ­ æƒ…ç»ªè¯†åˆ«"):
        if uploaded_video:
            video_raw_name = uploaded_video.name
            video_name = os.path.splitext(video_raw_name)[0]
            video_dir = os.path.join("G:/videochat/my_design/streamlit_save", video_name)
            os.makedirs(video_dir, exist_ok=True)

            video_path = os.path.join(video_dir, f"{video_name}.mp4")
            audio_path = os.path.join(video_dir, f"{video_name}.mp3")
            json_path = os.path.join(video_dir, f"{video_name}_transcription.json")

            # å¦‚æœ JSON ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨è½¬å½•ä¸€æ¬¡
            if not os.path.exists(json_path):
                # ä¿å­˜è§†é¢‘
                with open(video_path, "wb") as f:
                    f.write(uploaded_video.getbuffer())
                # æå–éŸ³é¢‘
                extract_audio_from_video(video_path, audio_path)
                # è¯­éŸ³è¯†åˆ«
                api_key = "sk-xxx"
                transcription = transcribe_audio(audio_path, api_key)
                with open(json_path, "w", encoding="utf-8") as f:
                    json.dump(transcription, f, ensure_ascii=False, indent=2)
            else:
                with open(json_path, "r", encoding="utf-8") as f:
                    transcription = json.load(f)

            # æå–æƒ…ç»ªå¹¶æ ¼å¼åŒ–è¾“å‡º
            emotion_lines = []
            for seg in transcription:
                start = seg.get("start")
                end = seg.get("end")
                text = seg.get("text", "")
                emotions = re.findall(r"[ğŸ˜€-ğŸ™âœ¨ğŸ’¥â¤ï¸ğŸŒŸğŸ˜ŠğŸ˜‚ğŸ˜¢ğŸ˜­ğŸ˜¡ğŸ˜ ğŸ‘ğŸ‘ğŸ’”ğŸ¤”ğŸ˜³ğŸ˜±ğŸ¤¯ğŸ˜´ğŸ˜ğŸ˜¬ğŸ˜‡ğŸ˜…ğŸ˜†ğŸ¥ºğŸ¥°ğŸ˜ğŸ˜˜ğŸ˜ğŸ˜“ğŸ˜©ğŸ˜¤ğŸ˜¨ğŸ˜°ğŸ˜ˆğŸ˜¶]", text)
                for emo in emotions:
                    line = f"åœ¨ {start:.2f} åˆ° {end:.2f} ç§’å†…ï¼Œæ£€æµ‹åˆ° {emo} æƒ…ç»ª"
                    emotion_lines.append(line)

            if emotion_lines:
                output_text = "æ£€æµ‹ç»“æœï¼š\n" + "\n".join(emotion_lines)
            else:
                output_text = "æœªæ£€æµ‹åˆ°æ˜æ˜¾æƒ…ç»ªç¬¦å·ã€‚"

        else:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶")



with b3:
    if st.button("ğŸ“½ï¸ è§†é¢‘æ€»ç»“"):
        if uploaded_video:
            video_name = os.path.splitext(uploaded_video.name)[0]
            video_dir = os.path.join("G:/videochat/my_design/streamlit_save", video_name)
            video_path = os.path.join(video_dir, f"{video_name}.mp4")
            json_path = os.path.join(video_dir, f"{video_name}_transcription.json")
            keyframe_json_path = os.path.join(video_dir, "keyframes_combined.json")
            summary_path = os.path.join(video_dir, f"{video_name}_summary.json")

            # è‹¥ keyframes ä¸å­˜åœ¨ï¼Œåˆ™è‡ªåŠ¨è°ƒç”¨å…¨æµç¨‹å¤„ç†ç”Ÿæˆ
            if not os.path.exists(keyframe_json_path):
                st.write("âš™ï¸ æ­£åœ¨æŠ½å–å…³é”®å¸§å¹¶ç”Ÿæˆ keyframes_combined.json ...")

                # ä¿å­˜è§†é¢‘ï¼ˆå¦‚æœªä¿å­˜ï¼‰
                with open(video_path, "wb") as f:
                    f.write(uploaded_video.getbuffer())

                # è°ƒç”¨è‡ªåŠ¨å¤„ç†
                process_video(
                    video_path=video_path,
                    output_dir=video_dir,
                    api_key="sk-e6f5a000ba014f92b4857a6dcd782591",
                    do_finetune=False
                )

            # åŠ è½½å…³é”®å¸§å›¾æ–‡ç»“æ„
            if os.path.exists(keyframe_json_path):
                with open(keyframe_json_path, "r", encoding="utf-8") as f:
                    keyframes_combined = json.load(f)

                summary = summarize_video_from_all_frames(
                    keyframes_combined=keyframes_combined,
                    api_key="sk-e6f5a000ba014f92b4857a6dcd782591",
                    output_summary_path=summary_path
                )

                if summary:
                    output_text = "ğŸ“½ï¸ è§†é¢‘æ€»ç»“ï¼š\n" + summary
                else:
                    output_text = "âŒ å¤§æ¨¡å‹æœªè¿”å›æœ‰æ•ˆæ€»ç»“å†…å®¹ï¼Œè¯·æ£€æŸ¥å…³é”®å¸§æ˜¯å¦å¼‚å¸¸ã€‚"
            else:
                output_text = "âŒ æ— æ³•è·å–å…³é”®å¸§ä¿¡æ¯ï¼Œè§†é¢‘æ€»ç»“å¤±è´¥ã€‚"
        else:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶")

with b4:
    if st.button("â˜ï¸ ç”Ÿæˆè¯äº‘å›¾"):
        st.success("âœ… è¯äº‘å›¾å·²ç”Ÿæˆï¼ˆæ¼”ç¤ºï¼‰")


# è·¯å¾„ä¿¡æ¯è¾“å‡º (ä¿®æ”¹ä¸ºåªæ˜¾ç¤ºå®é™…ä¿å­˜çš„æ–‡ä»¶)
if transcribe_triggered and uploaded_video:
    path_display = st.empty()
    with path_display.container():
        # ä¸å†æ˜¾ç¤º video_path
        # st.write(f"ğŸï¸ è§†é¢‘å·²ä¿å­˜ï¼š`{video_path}`")
        if 'audio_path' in locals() and os.path.exists(audio_path): # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„ç”Ÿæˆäº†
            st.write(f"ğŸ§ éŸ³é¢‘å·²ä¿å­˜ï¼š`{audio_path}`")
        if 'json_path' in locals() and os.path.exists(json_path):
            st.write(f"ğŸ“ åŸå§‹è½¬å½• JSONï¼š`{json_path}`")
        if 'text_path' in locals() and os.path.exists(text_path):
            st.write(f"ğŸ“„ æ¸…æ´—åæ–‡æœ¬ï¼š`{text_path}`")
    # å¯ä»¥è€ƒè™‘è®©è·¯å¾„ä¿¡æ¯åœç•™æ›´ä¹…æˆ–ä¸æ¶ˆå¤±
    # time.sleep(5)
    # path_display.empty()

# æ€»ç»“è¾“å‡º + å¯¹è¯åŒº (ä¿æŒä¸å˜)
#st.markdown("### ğŸ¤– è§†é¢‘æ€»ç»“ä¸æ™ºèƒ½é—®ç­”")
output_text_area = st.text_area("ğŸ“¤ è¾“å‡ºæ¡†", value=output_text, height=200) # ä½¿ç”¨æ–°å˜é‡åé¿å…å†²çª
question = st.text_input("ğŸ’¬ ä½ æƒ³é—®è¿™ä¸ªè§†é¢‘ä»€ä¹ˆï¼Ÿ")
if st.button("ğŸ’¡ æäº¤é—®é¢˜"):
    answer = f"è¿™æ˜¯å¯¹ä½ æé—®â€œ{question}â€çš„æ¨¡æ‹Ÿå›ç­”ï¼ˆæš‚æœªæ¥ APIï¼‰"
    st.text_area("ğŸ§  å¤§æ¨¡å‹å›ç­”", value=answer, height=100)