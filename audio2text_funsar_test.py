import time
import torch
from click.core import batch
from funasr import AutoModel
from tensorflow.python.data.experimental.ops.distribute import batch_sizes_for_worker

# ğŸ” æ£€æŸ¥ GPU çŠ¶æ€
print("ğŸ”§ CUDA æ˜¯å¦å¯ç”¨ï¼š", torch.cuda.is_available())
if torch.cuda.is_available():
    print("ğŸš€ å½“å‰ä½¿ç”¨ GPUï¼š", torch.cuda.get_device_name(0))
    device_type = "cuda"
else:
    print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU è¿è¡Œ")
    device_type = "cpu"

# â±ï¸ å¼€å§‹è®¡æ—¶
start_time = time.time()

# åˆå§‹åŒ–æ¨¡å‹
model = AutoModel(
    model="paraformer-zh",
    model_revision="v2.0.4",
    vad_model="fsmn-vad",
    punc_model="ct-punc",
    device=device_type  # âœ… è‡ªåŠ¨æ ¹æ®æ£€æµ‹ç»“æœåˆ‡æ¢
)

# éŸ³é¢‘è·¯å¾„
audio_path = r"G:\videochat\my_design\test_video.aac"
result = model.generate(input=audio_path,batch_size=16)

# ğŸ“„ æ‰“å°ç»“æœ
print("\nğŸ“„ è¯†åˆ«ç»“æœï¼š")
for seg in result:
    ts = seg["timestamp"]
    if isinstance(ts[0], list):
        t_start, t_end = ts[0]
    else:
        t_start, t_end = ts
    print(f"[{t_start/1000:.2f}s - {t_end/1000:.2f}s] {seg['text']}")

# â±ï¸ è®¡æ—¶ç»“æŸ
end_time = time.time()
print(f"\nâ±ï¸ è¯†åˆ«è€—æ—¶ï¼š{end_time - start_time:.2f} ç§’")
