import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import os
import matplotlib.pyplot as plt


class ClipAdaptor(nn.Module):
    """è½»é‡çº§CLIPç‰¹å¾é€‚é…å±‚
    Args:
        input_dim: CLIPç‰¹å¾ç»´åº¦ï¼ˆé»˜è®¤512ï¼‰
        hidden_dim: éšè—å±‚ç»´åº¦ï¼ˆé»˜è®¤256ï¼‰
        dropout: é˜²æ­¢è¿‡æ‹Ÿåˆï¼ˆé»˜è®¤0.1ï¼‰
    """

    def __init__(self, input_dim=512, hidden_dim=256, dropout=0.1):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.GELU(),
            nn.LayerNorm(hidden_dim),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, input_dim)
        )
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    def forward(self, x):
        if isinstance(x, list):
            x = torch.stack(x)
        return self.layers(x.to(self.device))


def train_adaptor(data_path, output_dir="adaptor_results", epochs=100, batch_size=16):
    """è®­ç»ƒé€‚é…å±‚çš„ä¸»å‡½æ•°
    Args:
        data_path: åŒ…å«CLIPç‰¹å¾çš„.pthæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼ˆä¿å­˜æ¨¡å‹å’Œæ—¥å¿—ï¼‰
        epochs: è®­ç»ƒè½®æ¬¡
        batch_size: æ‰¹å¤§å°
    Returns:
        trained_model: è®­ç»ƒå¥½çš„é€‚é…å±‚æ¨¡å‹
    """
    # åˆå§‹åŒ–ç¯å¢ƒ
    os.makedirs(output_dir, exist_ok=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # æ•°æ®åŠ è½½ä¸éªŒè¯
    try:
        data = torch.load(data_path)
        assert "image_feats" in data and "text_feats" in data
    except Exception as e:
        raise ValueError(f"æ•°æ®åŠ è½½å¤±è´¥: {e}ï¼Œè¯·æ£€æŸ¥{data_path}æ ¼å¼")

    # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨
    model = ClipAdaptor().to(device)
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)
    loss_fn = nn.CosineEmbeddingLoss()
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)

    # è®­ç»ƒå¾ªç¯
    losses = []
    best_loss = float('inf')
    progress_bar = tqdm(range(epochs), desc="è®­ç»ƒé€‚é…å±‚")

    for epoch in progress_bar:
        model.train()
        epoch_loss = 0
        indices = torch.randperm(len(data["image_feats"]))

        for i in range(0, len(indices), batch_size):
            batch_idx = indices[i:i + batch_size]
            batch_img = data["image_feats"][batch_idx].to(device).float()
            batch_txt = data["text_feats"][batch_idx].to(device).float()

            # å‰å‘ä¼ æ’­
            adapted_img = model(batch_img)
            loss = loss_fn(adapted_img, batch_txt, torch.ones(batch_img.size(0)).to(device))

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            epoch_loss += loss.item()

        # æ›´æ–°å­¦ä¹ ç‡å’Œè®°å½•
        scheduler.step()
        avg_loss = epoch_loss / (len(indices) / batch_size)
        losses.append(avg_loss)
        progress_bar.set_postfix({"loss": f"{avg_loss:.4f}"})

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save(model.state_dict(), os.path.join(output_dir, "best_adaptor.pth"))

    # ä¿å­˜è®­ç»ƒæ›²çº¿
    plt.figure()
    plt.plot(losses, label="Training Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Cosine Loss")
    plt.title("CLIP Adaptor Training")
    plt.savefig(os.path.join(output_dir, "loss_curve.png"))

    # åŠ è½½æœ€ä½³æ¨¡å‹è¿”å›
    model.load_state_dict(torch.load(os.path.join(output_dir, "best_adaptor.pth")))

    #éªŒè¯ï¼Ÿ
    model.eval()
    with torch.no_grad():
        sample_feat = data["image_feats"][:5].to(device).float()
        sample_text = data["text_feats"][:5].to(device).float()

        orig_sim = torch.cosine_similarity(sample_feat, sample_text, dim=1)
        adapted_sim = torch.cosine_similarity(model(sample_feat), sample_text, dim=1)

        print("\nğŸ” éªŒè¯ç»“æœå¯¹æ¯”ï¼ˆå‰5æ¡æ ·æœ¬ï¼‰ï¼š")
        print(f"åŸå§‹å›¾æ–‡ç›¸ä¼¼åº¦å‡å€¼:  {orig_sim.mean().item():.4f} Â± {orig_sim.std().item():.4f}")
        print(f"é€‚é…åå›¾æ–‡ç›¸ä¼¼åº¦å‡å€¼: {adapted_sim.mean().item():.4f} Â± {adapted_sim.std().item():.4f}")
    return model


# if __name__ == "__main__":
#     # ç¤ºä¾‹æµ‹è¯•ä»£ç 
#     test_data = {
#         "image_feats": torch.randn(100, 512),
#         "text_feats": torch.randn(100, 512)
#     }
#     torch.save(test_data, "test_features.pth")
#
#     model = train_adaptor("test_features.pth", epochs=3)
#     print(f"è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜åˆ° adaptor_results/")