# --- START OF FILE A_model_inference.py ---

import base64
import requests
import time
import json
import os
import torch
from dashscope import MultiModalConversation # å¯¼å…¥ DashScope å¤šæ¨¡æ€ä¼šè¯åº“
# å°è¯•å¯¼å…¥ CLIP Adaptor ç±»
try:
    from A_clip_finetune import ClipAdaptor
except ImportError:
    # å®šä¹‰ä¸€ä¸ªè™šæ‹Ÿç±»ï¼Œä»¥é˜² A_clip_finetune.py ä¸å­˜åœ¨æˆ– ClipAdaptor æœªå®šä¹‰
    class ClipAdaptor(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.linear = torch.nn.Linear(1, 1) # åŒ…å«ä¸€ä¸ªæ— æ„ä¹‰çš„å±‚
        def forward(self, x):
            print("è­¦å‘Š: æ­£åœ¨ä½¿ç”¨è™šæ‹Ÿ ClipAdaptorã€‚")
            return x

# --- å‡½æ•°ï¼šå¤„ç†æ‰€æœ‰å…³é”®å¸§å¹¶æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡ ---
def build_video_context(keyframes_combined, api_key, adaptor_path=None):
    """
    å¤„ç†è§†é¢‘çš„æ‰€æœ‰å…³é”®å¸§ï¼ˆå›¾åƒå’Œå…³è”æ–‡æœ¬ï¼‰ï¼Œä¸å¤§æ¨¡å‹é€å¸§äº¤äº’ï¼Œ
    æ„å»ºåŒ…å«è§†é¢‘å†…å®¹çš„å¯¹è¯å†å²ï¼ˆä¸Šä¸‹æ–‡ï¼‰ã€‚

    Args:
        keyframes_combined (list): åŒ…å«å…³é”®å¸§ä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ã€‚
                                   å­—å…¸åº”åŒ…å« 'image_path', 'mode', 'text'(å¯é€‰), 'timestamp' ç­‰é”®ã€‚
        api_key (str): ç”¨äºè°ƒç”¨å¤§æ¨¡å‹ API çš„å¯†é’¥ã€‚
        adaptor_path (str, optional): CLIP Adaptor æ¨¡å‹çš„æƒé‡æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæä¾›ä¸”æœ‰æ•ˆï¼Œ
                                      ä¼šå°è¯•åŠ è½½å¹¶ç”¨äºå¤„ç†å›¾åƒç‰¹å¾ï¼ˆå¦‚æœç‰¹å¾è·¯å¾„å­˜åœ¨ï¼‰ã€‚é»˜è®¤ä¸º Noneã€‚

    Returns:
        list: åŒ…å«ç³»ç»Ÿæç¤ºã€ç”¨æˆ·è¾“å…¥ï¼ˆå›¾æ–‡å¸§ï¼‰å’Œæ¨¡å‹ç¡®è®¤å›å¤çš„æ¶ˆæ¯åˆ—è¡¨ã€‚
              å¦‚æœå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œå¯èƒ½è¿”å› None æˆ–éƒ¨åˆ†ä¸Šä¸‹æ–‡ã€‚
    """
    # è®¾ç½®è®¡ç®—è®¾å¤‡ (GPU ä¼˜å…ˆ)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[æ¨¡å‹æ¨ç†] æ¨ç†è®¾å¤‡è®¾ç½®ä¸º: {device}")

    # --- åŠ è½½ CLIP é€‚é…å±‚ (Adaptor) ---
    adaptor = None # åˆå§‹åŒ–é€‚é…å±‚ä¸º None
    if adaptor_path and os.path.exists(adaptor_path):
        print(f"[æ¨¡å‹æ¨ç†] å°è¯•åŠ è½½é€‚é…å±‚: {adaptor_path}")
        adaptor = ClipAdaptor() # åˆ›å»ºé€‚é…å±‚å®ä¾‹
        try:
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            adaptor.load_state_dict(torch.load(adaptor_path, map_location=device))
            adaptor.to(device) # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            adaptor.eval()     # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            print(f"   âœ… é€‚é…å±‚å·²æˆåŠŸåŠ è½½åˆ° {device}ã€‚")
        except Exception as e:
            print(f"   âŒ åŠ è½½é€‚é…å±‚å¤±è´¥: {e}. å°†ä¸ä½¿ç”¨é€‚é…å±‚ã€‚")
            adaptor = None # åŠ è½½å¤±è´¥åˆ™é‡ç½®ä¸º None
    else:
        if adaptor_path:
            print(f"[æ¨¡å‹æ¨ç†] âš ï¸ æœªæ‰¾åˆ°é€‚é…å±‚æ–‡ä»¶ ({adaptor_path})ï¼Œå°†ä¸ä½¿ç”¨é€‚é…å±‚ã€‚")
        else:
             print("[æ¨¡å‹æ¨ç†] âš ï¸ æœªæä¾›é€‚é…å±‚è·¯å¾„ï¼Œå°†ä¸ä½¿ç”¨é€‚é…å±‚ã€‚")


    # --- ç³»ç»Ÿæç¤º (System Prompt) ---
    # æŒ‡å¯¼å¤§æ¨¡å‹æ‰®æ¼”çš„è§’è‰²å’Œä»»åŠ¡
    initial_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIè§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»”ç»†è§‚å¯Ÿå¹¶ç†è§£æŒ‰æ—¶é—´é¡ºåºç»™å‡ºçš„è§†é¢‘å…³é”®å¸§å›¾åƒå’Œå¯¹åº”çš„è¯­éŸ³è½¬å½•æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰ã€‚"
        "è¯·åœ¨æ¥æ”¶æ¯ä¸€å¸§ä¿¡æ¯æ—¶ï¼Œä¸“æ³¨äºç†è§£å½“å‰å¸§çš„æ ¸å¿ƒå†…å®¹ï¼Œå¹¶ç”¨ç®€çŸ­çš„è¯è¯­ç¡®è®¤ä½ å·²æ¥æ”¶å’Œç†è§£ï¼ˆä¾‹å¦‚ï¼Œâ€œå·²æ¥æ”¶å¸§ Xï¼Œå†…å®¹æ˜¯...â€æˆ–â€œå·²ç†è§£â€ï¼‰ï¼Œä¸è¦è¿›è¡Œæ€»ç»“æˆ–å›ç­”é—®é¢˜ã€‚"
        "åœ¨ç­‰å¾…åˆ°æˆ‘çš„æ€»ç»“æˆ–è€…é—®ç­”è¯·æ±‚æŒ‡ä»¤åï¼Œæˆ‘ä¼šæ˜ç¡®è¦æ±‚ä½ è¿›è¡Œæ€»ç»“æˆ–å›ç­”ç‰¹å®šé—®é¢˜ã€‚"
    )
    # åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç³»ç»Ÿæç¤º
    messages = [
        {
            "role":"system",    # è§’è‰²ï¼šç³»ç»Ÿ
            "content":[{"text":initial_prompt}]
        }
    ]

    print(f"[æ¨¡å‹æ¨ç†] å¼€å§‹å¤„ç† {len(keyframes_combined)} ä¸ªå…³é”®å¸§ä»¥æ„å»ºä¸Šä¸‹æ–‡...")
    # --- éå†å¤„ç†æ¯ä¸ªå…³é”®å¸§ ---
    for i, frame in enumerate(keyframes_combined):
        print(f"\n--- å¤„ç†å¸§ {i+1}/{len(keyframes_combined)} ---")
        image_feat_adapted = None # é‡ç½®è¯¥å¸§çš„é€‚é…å±‚å¤„ç†åç‰¹å¾

        # --- ï¼ˆå¯é€‰ï¼‰å¤„ç†å’Œåº”ç”¨ Adaptor ---
        # è¿™ä¸ªéƒ¨åˆ†æ˜¯åŸºäºåŸå§‹ä»£ç é€»è¾‘ï¼Œå‡è®¾å…³é”®å¸§å­—å…¸ä¸­å¯èƒ½åŒ…å« 'feat_path'
        # æ³¨æ„ï¼šä¸‹é¢çš„æ¨¡å‹è°ƒç”¨ MultiModalConversation.call é€šå¸¸åªæ¥å—å›¾åƒè·¯å¾„ï¼Œ
        # ä¸ç›´æ¥æ¥å—ç‰¹å¾å‘é‡ã€‚è¿™é‡Œçš„ç‰¹å¾å¤„ç†å¯èƒ½æ˜¯ä¸ºäº†å…¶ä»–ç›®çš„æˆ–éœ€è¦é€‚é…APIã€‚
        feat_path = frame.get("feat_path")
        if feat_path and adaptor and os.path.exists(feat_path):
            # åªæœ‰å½“ç‰¹å¾è·¯å¾„å­˜åœ¨ã€é€‚é…å±‚åŠ è½½æˆåŠŸã€ä¸”æ–‡ä»¶å­˜åœ¨æ—¶æ‰å¤„ç†
            print(f"   æ£€æµ‹åˆ°ç‰¹å¾æ–‡ä»¶: {feat_path}ï¼Œå°è¯•åº”ç”¨é€‚é…å±‚...")
            try:
                # åŠ è½½ç‰¹å¾æ•°æ®
                feat_data = torch.load(feat_path, map_location=device)
                if "image_feat" in feat_data:
                    image_feat = feat_data["image_feat"] # è·å–å›¾åƒç‰¹å¾
                    # ç¡®ä¿æ•°æ®ç±»å‹ä¸º float32
                    if image_feat.dtype != torch.float32:
                        image_feat = image_feat.float()

                    # åº”ç”¨é€‚é…å±‚
                    with torch.no_grad(): # å…³é—­æ¢¯åº¦è®¡ç®—
                         image_feat_adapted = adaptor(image_feat).cpu() # å¤„ç†åç§»åˆ° CPU (å¦‚æœåç»­éœ€è¦)
                    print("      âœ… é€‚é…å±‚å·²åº”ç”¨äºç‰¹å¾ã€‚")
                    # æ³¨æ„ï¼šimage_feat_adapted å¹¶æœªåœ¨åç»­è°ƒç”¨ä¸­ç›´æ¥ä½¿ç”¨
                else:
                    print(f"      âš ï¸ ç‰¹å¾æ–‡ä»¶ {feat_path} ä¸­ç¼ºå°‘ 'image_feat' é”®ã€‚")
            except Exception as e:
                print(f"      âŒ å¤„ç†ç‰¹å¾æ–‡ä»¶ {feat_path} æ—¶å‡ºé”™: {e}")
        # else:
        #     if feat_path and not adaptor: print("   ç‰¹å¾æ–‡ä»¶å­˜åœ¨ä½†é€‚é…å±‚æœªåŠ è½½ï¼Œè·³è¿‡é€‚é…å±‚å¤„ç†ã€‚")
        #     elif feat_path and not os.path.exists(feat_path): print(f"   ç‰¹å¾æ–‡ä»¶è·¯å¾„æ— æ•ˆ: {feat_path}")


        # --- æ„é€ å‘é€ç»™æ¨¡å‹çš„æ–‡æœ¬æç¤º ---
        text_prompt_content = "" # åˆå§‹åŒ–æ–‡æœ¬å†…å®¹
        frame_mode = frame.get("mode", "unknown")   # è·å–å¸§æ¨¡å¼
        timestamp = frame.get('timestamp', '?')     # è·å–æ—¶é—´æˆ³
        image_path = frame.get("image_path", "")    # è·å–å›¾åƒè·¯å¾„

        # æ£€æŸ¥å›¾åƒè·¯å¾„æ˜¯å¦æœ‰æ•ˆ
        if not image_path or not os.path.exists(image_path):
             print(f"   âŒ é”™è¯¯ï¼šå¸§ {i+1} çš„å›¾åƒæ–‡ä»¶è·¯å¾„ '{image_path}' æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ­¤å¸§ã€‚")
             continue # è·³è¿‡æ— æ³•å¤„ç†çš„å¸§

        # æ ¹æ®å¸§æ¨¡å¼ç”Ÿæˆä¸åŒçš„æç¤ºæ–‡æœ¬
        if frame_mode == "text_guided":
            # æ–‡æœ¬å¼•å¯¼å¸§ï¼šåŒ…å«æ–‡æœ¬ã€æ—¶é—´ç­‰ä¿¡æ¯
            segment_idx = frame.get('segment_idx', 'N/A')
            text = frame.get('text', 'æ— æ–‡æœ¬').strip()
            start_time = frame.get('start', '?')
            end_time = frame.get('end', '?')
            similarity = frame.get('similarity', 'N/A') # è·å–ç›¸ä¼¼åº¦ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            text_prompt_content = (
                f"å¸§ {i+1}/{len(keyframes_combined)} (æ–‡æœ¬å¼•å¯¼æ¨¡å¼): \n"
                f"å¯¹åº”è¯­éŸ³æ®µ: {segment_idx} (æ—¶é—´: {start_time}s - {end_time}s)\n"
                f"è¯­éŸ³æ–‡æœ¬: â€œ{text}â€\n"
                f"å›¾åƒæ—¶é—´æˆ³: {timestamp}s\n"
                # f"å›¾æ–‡ç›¸ä¼¼åº¦: {similarity}\n" # (å¯é€‰) åŠ å…¥ç›¸ä¼¼åº¦ä¿¡æ¯
                f"è¯·ç†è§£ä»¥ä¸Šå›¾æ–‡ä¿¡æ¯å¹¶ç¡®è®¤æ¥æ”¶ã€‚"
            )
        elif frame_mode == "visual_compensate":
            # è§†è§‰è¡¥å¿å¸§ï¼šé€šå¸¸åœ¨é™é»˜åŒºé—´
            start = frame.get('start', '?')
            end = frame.get('end', '?')
            text_prompt_content = (
                f"å¸§ {i+1}/{len(keyframes_combined)} (è§†è§‰è¡¥å¿æ¨¡å¼): \n"
                f"ä½äºé™é»˜åŒºé—´: {start}s - {end}s\n"
                f"å›¾åƒæ—¶é—´æˆ³: {timestamp}s\n"
                f"è¯·ç†è§£å›¾åƒå†…å®¹å¹¶ç¡®è®¤æ¥æ”¶ã€‚"
            )
        elif frame_mode == "visual_guided":
             # çº¯è§†è§‰å¸§
             importance = frame.get('importance', 'N/A')
             text_prompt_content = (
                 f"å¸§ {i+1}/{len(keyframes_combined)} (çº¯è§†è§‰æ¨¡å¼): \n"
                 f"å›¾åƒæ—¶é—´æˆ³: {timestamp}s\n"
                 # f"è§†è§‰é‡è¦æ€§: {importance}\n" # (å¯é€‰) åŠ å…¥é‡è¦æ€§ä¿¡æ¯
                 f"è¯·è§‚å¯Ÿå›¾åƒå¹¶ç¡®è®¤æ¥æ”¶ã€‚"
             )
        else: # å…¶ä»–æœªçŸ¥æ¨¡å¼
            text_prompt_content = (
                f"å¸§ {i+1}/{len(keyframes_combined)} (æ¨¡å¼: {frame_mode}): \n"
                f"å›¾åƒæ—¶é—´æˆ³: {timestamp}s\n"
                f"è¯·ç†è§£å›¾åƒå†…å®¹å¹¶ç¡®è®¤æ¥æ”¶ã€‚"
            )

        # --- å‡†å¤‡å‘é€ç»™å¤§æ¨¡å‹çš„æ¶ˆæ¯ä½“ ---
        user_msg_content = [
            {"image": image_path},      # å›¾åƒå†…å®¹ï¼Œä½¿ç”¨æ–‡ä»¶è·¯å¾„
            {"text": text_prompt_content} # æ–‡æœ¬æç¤º
        ]
        user_msg = {
            "role": "user", # è§’è‰²ï¼šç”¨æˆ·
            "content": user_msg_content
        }
        #æµ‹è¯•æ—¶é—´1
        test_start_1 = time.time()
        # --- æ‰“å°å°†è¦å‘é€çš„å†…å®¹ (è°ƒè¯•ç”¨) ---
        print(f"\n   ğŸ“ å‘é€ç»™æ¨¡å‹ (å¸§ {i+1}):")
        print(f"      å›¾åƒ: {image_path}")
        print(f"      æ–‡æœ¬: {text_prompt_content}")

        # --- è°ƒç”¨å¤§æ¨¡å‹ API å¤„ç†å½“å‰å¸§ ---
        try:
            # åªå‘é€å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼Œè®©æ¨¡å‹å¤„ç†è¿™ä¸€å¸§çš„ä¿¡æ¯
            response = MultiModalConversation.call(
                api_key=api_key,              # ä½¿ç”¨ä¼ å…¥çš„ API Key
                model='qwen-vl-plus-latest', # æŒ‡å®šæ¨¡å‹ (ç¡®ä¿å¯ç”¨)
                messages=[user_msg]           # åªåŒ…å«å½“å‰å¸§çš„æ¶ˆæ¯
            )

            # --- è§£ææ¨¡å‹çš„å›å¤ ---
            reply_text = "æ¨¡å‹æœªè¿”å›æœ‰æ•ˆç¡®è®¤æ–‡æœ¬ã€‚" # è®¾ç½®é»˜è®¤å›å¤
            # ä¸¥æ ¼æ£€æŸ¥è¿”å›ç»“æœçš„ç»“æ„
            if (response and isinstance(response, dict) and
                response.get('status_code') == 200 and # çŠ¶æ€ç  200 è¡¨ç¤ºæˆåŠŸ
                response.get('output') and isinstance(response['output'], dict) and
                response['output'].get('choices') and isinstance(response['output']['choices'], list) and
                len(response['output']['choices']) > 0 and # choices åˆ—è¡¨ä¸ä¸ºç©º
                response['output']['choices'][0].get('message') and isinstance(response['output']['choices'][0]['message'], dict) and
                response['output']['choices'][0]['message'].get('content') and isinstance(response['output']['choices'][0]['message']['content'], list) and
                len(response['output']['choices'][0]['message']['content']) > 0 and # content åˆ—è¡¨ä¸ä¸ºç©º
                response['output']['choices'][0]['message']['content'][0].get('text')): # æ–‡æœ¬å†…å®¹å­˜åœ¨

                # æå–æ¨¡å‹å›å¤çš„æ–‡æœ¬
                reply_text = response['output']['choices'][0]['message']['content'][0]['text']
                print(f"   âœ… æ¨¡å‹å›å¤ (å¸§ {i+1}): {reply_text[:150]}...") # æ‰“å°å›å¤çš„å‰150ä¸ªå­—ç¬¦
                #æµ‹è¯•æ—¶é—´2
                test_start_2 = time.time()
                print(f"apiå¤„ç†æ—¶é—´ï¼š{test_start_2 - test_start_1:.4f} ç§’")
            else:
                # å¦‚æœå“åº”ç»“æ„ä¸ç¬¦åˆé¢„æœŸï¼Œæ‰“å°è­¦å‘Šå’Œå®Œæ•´çš„å“åº”å†…å®¹
                print(f"   âš ï¸ æ¨¡å‹è¿”å›ç»“æ„å¼‚å¸¸æˆ–æ— æœ‰æ•ˆæ–‡æœ¬ç¡®è®¤ (å¸§ {i+1})ã€‚Response: {response}")

        except Exception as e:
            # æ•è·è°ƒç”¨ API æ—¶çš„å¼‚å¸¸
            print(f"   âŒ è°ƒç”¨æ¨¡å‹å¤„ç†å¸§ {i+1} æ—¶å‡ºé”™: {e}")
            # è®°å½•é”™è¯¯ä¿¡æ¯ä½œä¸ºæ¨¡å‹çš„å›å¤
            reply_text = f"å¤„ç†å¸§æ—¶å‘ç”Ÿé”™è¯¯: {e}"

        # --- å°†ç”¨æˆ·çš„æ¶ˆæ¯å’Œæ¨¡å‹çš„å›å¤ï¼ˆæˆ–é”™è¯¯ä¿¡æ¯ï¼‰æ·»åŠ åˆ°æ€»çš„å¯¹è¯å†å²ä¸­ ---
        messages.append(user_msg) # æ·»åŠ ç”¨æˆ·å‘é€çš„æ¶ˆæ¯
        messages.append({
            "role": "assistant", # è§’è‰²ï¼šåŠ©æ‰‹ (ä»£è¡¨æ¨¡å‹çš„å›å¤)
            "content": [{"text": reply_text}]
        })

        # æ§åˆ¶ API è°ƒç”¨é¢‘ç‡ï¼Œé˜²æ­¢è¿‡äºé¢‘ç¹è¯·æ±‚ (æ ¹æ® API æä¾›å•†çš„é™åˆ¶è°ƒæ•´)
        time.sleep(1)

    print("\n[æ¨¡å‹æ¨ç†] âœ… æ‰€æœ‰å¸§å¤„ç†å®Œæ¯•ï¼Œè§†é¢‘ä¸Šä¸‹æ–‡å·²æ„å»ºå®Œæˆã€‚")
    return messages # è¿”å›åŒ…å«å®Œæ•´å¯¹è¯å†å²çš„æ¶ˆæ¯åˆ—è¡¨

# --- å‡½æ•°ï¼šåŸºäºæ„å»ºå¥½çš„ä¸Šä¸‹æ–‡ç”Ÿæˆæ€»ç»“ ---
def generate_summary_from_context(messages_context, api_key, output_summary_path=None):
    """
    ä½¿ç”¨é¢„å…ˆæ„å»ºå¥½çš„åŒ…å«è§†é¢‘å†…å®¹çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œè¯·æ±‚å¤§æ¨¡å‹ç”Ÿæˆè§†é¢‘æ€»ç»“ã€‚

    Args:
        messages_context (list): åŒ…å«å®Œæ•´å¯¹è¯å†å²çš„æ¶ˆæ¯åˆ—è¡¨ã€‚
        api_key (str): API å¯†é’¥ã€‚
        output_summary_path (str, optional): å¦‚æœæä¾›ï¼Œåˆ™å°†ç”Ÿæˆçš„æ€»ç»“ä¿å­˜åˆ°æ­¤è·¯å¾„çš„ JSON æ–‡ä»¶ä¸­ã€‚

    Returns:
        str: ç”Ÿæˆçš„è§†é¢‘æ€»ç»“æ–‡æœ¬ã€‚å¦‚æœå¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    if not messages_context:
        print("[æ¨¡å‹æ¨ç†] âŒ æ— æ³•ç”Ÿæˆæ€»ç»“ï¼Œå› ä¸ºè¾“å…¥çš„ä¸Šä¸‹æ–‡ä¸ºç©ºã€‚")
        return None

    # åˆ›å»ºä¸Šä¸‹æ–‡åˆ—è¡¨çš„å‰¯æœ¬ï¼Œä»¥å…ä¿®æ”¹åŸå§‹åˆ—è¡¨
    summary_messages = list(messages_context)

    # --- æ·»åŠ æœ€ç»ˆçš„æ€»ç»“æŒ‡ä»¤ ---
    final_prompt = "ç°åœ¨ï¼Œè¯·æ ¹æ®ä»¥ä¸Šæˆ‘ä»¬äº¤äº’çš„æ‰€æœ‰è§†é¢‘å¸§å›¾åƒã€å¯¹åº”çš„æ–‡æœ¬ä¿¡æ¯ä»¥åŠä½ çš„ç†è§£ï¼Œå¯¹æ•´ä¸ªè§†é¢‘å†…å®¹è¿›è¡Œä¸€ä¸ªå…¨é¢ã€è¿è´¯çš„æ€»ç»“ã€‚è¯·ç›´æ¥è¾“å‡ºæ€»ç»“å†…å®¹ï¼Œé¿å…åŒ…å«è¯¸å¦‚â€œå¥½çš„ï¼Œè¿™æ˜¯æ€»ç»“ï¼šâ€æˆ–â€œæ€»ç»“å¦‚ä¸‹ï¼šâ€ç­‰é¢å¤–è¯­å¥ã€‚"
    summary_messages.append({
        "role": "user", # è§’è‰²ï¼šç”¨æˆ· (æå‡ºæ€»ç»“è¯·æ±‚)
        "content": [{"text": final_prompt}]
    })

    print("\n[æ¨¡å‹æ¨ç†] ğŸ’¡ æ­£åœ¨è¯·æ±‚æ¨¡å‹ç”Ÿæˆè§†é¢‘æ€»ç»“...")
    try:
        # è°ƒç”¨å¤§æ¨¡å‹ APIï¼Œå‘é€åŒ…å«å®Œæ•´å†å²å’Œæ€»ç»“è¯·æ±‚çš„æ¶ˆæ¯åˆ—è¡¨
        response = MultiModalConversation.call(
            api_key=api_key,
            model='qwen-vl-plus-latest',
            messages=summary_messages # å‘é€å®Œæ•´ä¸Šä¸‹æ–‡
        )

        # --- è§£ææ€»ç»“å“åº” ---
        summary = None # åˆå§‹åŒ–æ€»ç»“å˜é‡
        # åŒæ ·è¿›è¡Œä¸¥æ ¼çš„ç»“æ„æ£€æŸ¥
        if (response and isinstance(response, dict) and
            response.get('status_code') == 200 and
            response.get('output') and isinstance(response['output'], dict) and
            response['output'].get('choices') and isinstance(response['output']['choices'], list) and
            len(response['output']['choices']) > 0 and
            response['output']['choices'][0].get('message') and isinstance(response['output']['choices'][0]['message'], dict) and
            response['output']['choices'][0]['message'].get('content') and isinstance(response['output']['choices'][0]['message']['content'], list) and
            len(response['output']['choices'][0]['message']['content']) > 0 and
            response['output']['choices'][0]['message']['content'][0].get('text')):

            # æå–æ€»ç»“æ–‡æœ¬
            summary = response['output']['choices'][0]['message']['content'][0]['text'].strip() # å»é™¤å¯èƒ½çš„é¦–å°¾ç©ºæ ¼
            print(f"[æ¨¡å‹æ¨ç†] âœ… è§†é¢‘æ€»ç»“å®Œæˆ:\n{summary}")

            # --- å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œåˆ™ä¿å­˜æ€»ç»“ ---
            if output_summary_path:
                 print(f"   ğŸ’¾ æ­£åœ¨å°è¯•ä¿å­˜æ€»ç»“åˆ°: {output_summary_path}")
                 # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                 summary_dir = os.path.dirname(output_summary_path)
                 if summary_dir: # æ£€æŸ¥ç›®å½•åéç©º
                     os.makedirs(summary_dir, exist_ok=True)

                 try:
                     # å°†æ€»ç»“ä¿å­˜ä¸º {"summary": "æ€»ç»“å†…å®¹..."} æ ¼å¼çš„ JSON
                     with open(output_summary_path, "w", encoding="utf-8") as f:
                         json.dump({"summary": summary}, f, ensure_ascii=False, indent=2)
                     print(f"      âœ… æ€»ç»“å·²æˆåŠŸä¿å­˜ã€‚")
                 except Exception as e_write:
                     print(f"      âŒ ä¿å­˜æ€»ç»“æ–‡ä»¶åˆ° {output_summary_path} æ—¶å‡ºé”™: {e_write}")

            return summary # è¿”å›æ€»ç»“æ–‡æœ¬
        else:
            # å¦‚æœå“åº”ç»“æ„ä¸ç¬¦åˆé¢„æœŸ
            print(f"[æ¨¡å‹æ¨ç†] âŒ æ¨¡å‹æœªè¿”å›æœ‰æ•ˆçš„æ€»ç»“å†…å®¹ã€‚Response: {response}")
            return None

    except Exception as e:
        # å¦‚æœè°ƒç”¨ API ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™
        print(f"[æ¨¡å‹æ¨ç†] âŒ è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™: {e}")
        return None

# --- æ–°å¢å‡½æ•°ï¼šåŸºäºä¸Šä¸‹æ–‡è¿›è¡Œé—®ç­” ---
def ask_question_about_video(messages_context, question, api_key):
    """
    ä½¿ç”¨é¢„å…ˆæ„å»ºå¥½çš„è§†é¢‘å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå‘å¤§æ¨¡å‹æå‡ºå…³äºè§†é¢‘å†…å®¹çš„å…·ä½“é—®é¢˜ã€‚

    Args:
        messages_context (list): åŒ…å«è§†é¢‘å†…å®¹çš„å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨ã€‚
        question (str): ç”¨æˆ·æå‡ºçš„å…³äºè§†é¢‘å†…å®¹çš„é—®é¢˜ã€‚
        api_key (str): API å¯†é’¥ã€‚

    Returns:
        str: å¤§æ¨¡å‹é’ˆå¯¹é—®é¢˜çš„å›ç­”ã€‚å¦‚æœå‡ºé”™æˆ–æ— æ³•å›ç­”ï¼Œåˆ™è¿”å›ç›¸åº”çš„é”™è¯¯ä¿¡æ¯ã€‚
    """
    # --- è¾“å…¥æ£€æŸ¥ ---
    if not messages_context:
        print("[æ¨¡å‹æ¨ç†] âŒ æ— æ³•å›ç­”é—®é¢˜ï¼Œå› ä¸ºè§†é¢‘ä¸Šä¸‹æ–‡ä¸ºç©ºã€‚")
        return "é”™è¯¯ï¼šè§†é¢‘ä¸Šä¸‹æ–‡å°šæœªå»ºç«‹ï¼Œè¯·å…ˆè¿è¡Œâ€œè§†é¢‘æ€»ç»“â€åŠŸèƒ½ã€‚"
    if not question or not question.strip(): # æ£€æŸ¥é—®é¢˜æ˜¯å¦ä¸ºç©ºæˆ–ä»…åŒ…å«ç©ºæ ¼
        print("[æ¨¡å‹æ¨ç†] âŒ é—®é¢˜ä¸ºç©ºï¼Œæ— æ³•æé—®ã€‚")
        return "é”™è¯¯ï¼šè¯·è¾“å…¥æ‚¨æƒ³é—®çš„é—®é¢˜ã€‚"

    # --- å‡†å¤‡é—®ç­”æ¶ˆæ¯åˆ—è¡¨ ---
    # åˆ›å»ºä¸Šä¸‹æ–‡åˆ—è¡¨çš„å‰¯æœ¬ï¼Œé¿å…å½±å“åŸå§‹ä¸Šä¸‹æ–‡
    qa_messages = list(messages_context)

    # --- æ·»åŠ ç”¨æˆ·çš„é—®é¢˜ ---
    # å¯ä»¥è€ƒè™‘åœ¨é—®é¢˜å‰åŠ ä¸Šå¼•å¯¼ï¼Œå¸®åŠ©æ¨¡å‹èšç„¦
    qa_prompt = f"åŸºäºä»¥ä¸Šä½ å¯¹è§†é¢‘å†…å®¹çš„ç†è§£ï¼Œè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š\n\né—®é¢˜ï¼š{question}\n\nè¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆã€‚"
    qa_messages.append({
        "role": "user", # è§’è‰²ï¼šç”¨æˆ· (æå‡ºé—®é¢˜)
        "content": [{"text": qa_prompt}]
        # "content": [{"text": question}] # æˆ–è€…ç›´æ¥å‘é€é—®é¢˜
    })

    print(f"\n[æ¨¡å‹æ¨ç†] â“ æ­£åœ¨å‘æ¨¡å‹æé—®ï¼š{question}")
    try:
        # --- è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œé—®ç­” ---
        response = MultiModalConversation.call(
            api_key=api_key,
            model='qwen-vl-plus-latest', # ä½¿ç”¨ä¸ä¹‹å‰ç›¸åŒçš„æ¨¡å‹
            messages=qa_messages       # å‘é€åŒ…å«ä¸Šä¸‹æ–‡å’Œé—®é¢˜çš„æ¶ˆæ¯åˆ—è¡¨
        )

        # --- è§£æé—®ç­”å“åº” ---
        answer = f"æ¨¡å‹æœªèƒ½å›ç­”è¯¥é—®é¢˜ (çŠ¶æ€ç : {response.get('status_code', 'N/A')})ã€‚" # é»˜è®¤é”™è¯¯å›ç­”
        # ä¸¥æ ¼æ£€æŸ¥å“åº”ç»“æ„
        if (response and isinstance(response, dict) and
            response.get('status_code') == 200 and
            response.get('output') and isinstance(response['output'], dict) and
            response['output'].get('choices') and isinstance(response['output']['choices'], list) and
            len(response['output']['choices']) > 0 and
            response['output']['choices'][0].get('message') and isinstance(response['output']['choices'][0]['message'], dict) and
            response['output']['choices'][0]['message'].get('content') and isinstance(response['output']['choices'][0]['message']['content'], list) and
            len(response['output']['choices'][0]['message']['content']) > 0 and
            response['output']['choices'][0]['message']['content'][0].get('text')):

            # æå–ç­”æ¡ˆæ–‡æœ¬
            answer = response['output']['choices'][0]['message']['content'][0]['text'].strip()
            print(f"[æ¨¡å‹æ¨ç†] ğŸ’¡ æ¨¡å‹å›ç­”:\n{answer}")

        else:
            # å¦‚æœå“åº”ç»“æ„ä¸ç¬¦åˆé¢„æœŸ
            print(f"[æ¨¡å‹æ¨ç†] âŒ æ¨¡å‹æœªè¿”å›æœ‰æ•ˆçš„å›ç­”ã€‚Response: {response}")

        return answer # è¿”å›ç­”æ¡ˆæ–‡æœ¬æˆ–é”™è¯¯ä¿¡æ¯

    except Exception as e:
        # å¦‚æœè°ƒç”¨ API å›ç­”é—®é¢˜æ—¶å‡ºé”™
        print(f"[æ¨¡å‹æ¨ç†] âŒ è°ƒç”¨æ¨¡å‹å›ç­”é—®é¢˜æ—¶å‡ºé”™: {e}")
        return f"è°ƒç”¨APIå›ç­”é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {e}"


# --- é‡æ„åçš„åŸå§‹å‡½æ•° (å¯ä»¥ä¿ç•™ä½œä¸ºæ•´ä½“æµç¨‹çš„è°ƒç”¨å…¥å£) ---
def summarize_video_from_all_frames(keyframes_combined, api_key, adaptor_path=None, output_summary_path=None):
    """
    ï¼ˆé‡æ„åï¼‰æ‰§è¡Œå®Œæ•´çš„è§†é¢‘å¤„ç†æµç¨‹ï¼šæ„å»ºä¸Šä¸‹æ–‡ -> ç”Ÿæˆæ€»ç»“ã€‚

    Args:
        keyframes_combined (list): å…³é”®å¸§æ•°æ®åˆ—è¡¨ã€‚
        api_key (str): API å¯†é’¥ã€‚
        adaptor_path (str, optional): Adaptor è·¯å¾„ã€‚
        output_summary_path (str, optional): æ€»ç»“ä¿å­˜è·¯å¾„ã€‚

    Returns:
        tuple: (æ€»ç»“æ–‡æœ¬, æ¶ˆæ¯ä¸Šä¸‹æ–‡åˆ—è¡¨) æˆ– (None, None) å¦‚æœå¤±è´¥ã€‚
               è¿”å›ä¸Šä¸‹æ–‡æ˜¯ä¸ºäº†è®©è°ƒç”¨è€…ï¼ˆå¦‚ Streamlit UIï¼‰å¯ä»¥ä¿å­˜å®ƒç”¨äºåç»­é—®ç­”ã€‚
    """
    print("--- å¼€å§‹æ‰§è¡Œå®Œæ•´æµç¨‹ï¼šæ„å»ºä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆæ€»ç»“ ---")
    # æ­¥éª¤ 1: æ„å»ºè§†é¢‘ä¸Šä¸‹æ–‡
    print("   æ­¥éª¤ 1: æ„å»ºè§†é¢‘ä¸Šä¸‹æ–‡...")
    messages_context = build_video_context(keyframes_combined, api_key, adaptor_path)

    # æ­¥éª¤ 2: åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆæ€»ç»“ (ä»…å½“ä¸Šä¸‹æ–‡æ„å»ºæˆåŠŸæ—¶)
    if messages_context:
        print("\n   æ­¥éª¤ 2: åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆè§†é¢‘æ€»ç»“...")
        summary = generate_summary_from_context(messages_context, api_key, output_summary_path)
        # è¿”å›æ€»ç»“æ–‡æœ¬å’Œæ„å»ºå¥½çš„ä¸Šä¸‹æ–‡
        return summary, messages_context
    else:
        # å¦‚æœä¸Šä¸‹æ–‡æ„å»ºå¤±è´¥ï¼Œåˆ™æ— æ³•è¿›è¡Œæ€»ç»“
        print("âŒ æ„å»ºè§†é¢‘ä¸Šä¸‹æ–‡å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ç”Ÿæˆæ€»ç»“ã€‚")
        # è¿”å› None è¡¨ç¤ºå¤±è´¥
        return None, None